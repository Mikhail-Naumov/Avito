{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook To Do:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translation:\n",
    "Russian NLP:\n",
    "- http://www.redhenlab.org/home/the-cognitive-core-research-topics-in-red-hen/the-barnyard/russian-nlp\n",
    "- https://github.com/named-entity/nltk4russian\n",
    "- https://github.com/nlpub/russe-evaluation/tree/master/russe/measures/word2vec\n",
    "\n",
    "#### Data Cleaning:\n",
    "- Are any nulls imputable?\n",
    "        \n",
    "#### Feature Engineering:\n",
    "- Generate # of words in (text features) column\n",
    "- Generate date_time features\n",
    "    - Day of week\n",
    "- Generate non-text charactor count in text features column\n",
    "    - \"#### BUY NOW ####\" ads\n",
    "    \n",
    "#### Model Design:\n",
    "- tfidf feels like the best choice\n",
    "- svd is a must\n",
    "- maybe nn but ive been having good luck in my last nlp project with lgbm\n",
    "\n",
    "#### Elevated Design:\n",
    "- adding image data\n",
    "    - Extracting features from images\n",
    "        - Color\n",
    "        - Size\n",
    "        - number of images\n",
    "        - look into image categorization... is there a way to measure image quality?\n",
    "        \n",
    "#### Quality of Life:\n",
    "- Memory Management\n",
    "- Commenting Process\n",
    "- Having Fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the kaggle test data\n",
    "use_test = True\n",
    "# train contains 1.5m+ entries, thus just using 25% of data\n",
    "use_25 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "periods_test.csv  test.csv          train.csv\r\n",
      "periods_train.csv test_active.csv   train_active.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Inputs/train.csv', parse_dates=[\"activation_date\"])\n",
    "if use_test: test = pd.read_csv('./Inputs/test.csv', parse_dates=[\"activation_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if use_25:\n",
    "    train = train[:round(train.shape[0]/4)]\n",
    "    test = test[:round(test.shape[0]/4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#train_active = pd.read_csv('./Inputs/train_active.csv')\n",
    "#periods_train = pd.read_csv('./Inputs/periods_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parent_category_name_map = {\"Личные вещи\" : \"Personal belongings\",\n",
    "                            \"Для дома и дачи\" : \"For the home and garden\",\n",
    "                            \"Бытовая электроника\" : \"Consumer electronics\",\n",
    "                            \"Недвижимость\" : \"Real estate\",\n",
    "                            \"Хобби и отдых\" : \"Hobbies & leisure\",\n",
    "                            \"Транспорт\" : \"Transport\",\n",
    "                            \"Услуги\" : \"Services\",\n",
    "                            \"Животные\" : \"Animals\",\n",
    "                            \"Для бизнеса\" : \"For business\"}\n",
    "\n",
    "region_map = {\"Свердловская область\" : \"Sverdlovsk oblast\",\n",
    "            \"Самарская область\" : \"Samara oblast\",\n",
    "            \"Ростовская область\" : \"Rostov oblast\",\n",
    "            \"Татарстан\" : \"Tatarstan\",\n",
    "            \"Волгоградская область\" : \"Volgograd oblast\",\n",
    "            \"Нижегородская область\" : \"Nizhny Novgorod oblast\",\n",
    "            \"Пермский край\" : \"Perm Krai\",\n",
    "            \"Оренбургская область\" : \"Orenburg oblast\",\n",
    "            \"Ханты-Мансийский АО\" : \"Khanty-Mansi Autonomous Okrug\",\n",
    "            \"Тюменская область\" : \"Tyumen oblast\",\n",
    "            \"Башкортостан\" : \"Bashkortostan\",\n",
    "            \"Краснодарский край\" : \"Krasnodar Krai\",\n",
    "            \"Новосибирская область\" : \"Novosibirsk oblast\",\n",
    "            \"Омская область\" : \"Omsk oblast\",\n",
    "            \"Белгородская область\" : \"Belgorod oblast\",\n",
    "            \"Челябинская область\" : \"Chelyabinsk oblast\",\n",
    "            \"Воронежская область\" : \"Voronezh oblast\",\n",
    "            \"Кемеровская область\" : \"Kemerovo oblast\",\n",
    "            \"Саратовская область\" : \"Saratov oblast\",\n",
    "            \"Владимирская область\" : \"Vladimir oblast\",\n",
    "            \"Калининградская область\" : \"Kaliningrad oblast\",\n",
    "            \"Красноярский край\" : \"Krasnoyarsk Krai\",\n",
    "            \"Ярославская область\" : \"Yaroslavl oblast\",\n",
    "            \"Удмуртия\" : \"Udmurtia\",\n",
    "            \"Алтайский край\" : \"Altai Krai\",\n",
    "            \"Иркутская область\" : \"Irkutsk oblast\",\n",
    "            \"Ставропольский край\" : \"Stavropol Krai\",\n",
    "            \"Тульская область\" : \"Tula oblast\"}\n",
    "\n",
    "\n",
    "category_map = {\"Одежда, обувь, аксессуары\":\"Clothing, shoes, accessories\",\n",
    "                \"Детская одежда и обувь\":\"Children's clothing and shoes\",\n",
    "                \"Товары для детей и игрушки\":\"Children's products and toys\",\n",
    "                \"Квартиры\":\"Apartments\",\n",
    "                \"Телефоны\":\"Phones\",\n",
    "                \"Мебель и интерьер\":\"Furniture and interior\",\n",
    "                \"Предложение услуг\":\"Offer services\",\n",
    "                \"Автомобили\":\"Cars\",\n",
    "                \"Ремонт и строительство\":\"Repair and construction\",\n",
    "                \"Бытовая техника\":\"Appliances\",\n",
    "                \"Товары для компьютера\":\"Products for computer\",\n",
    "                \"Дома, дачи, коттеджи\":\"Houses, villas, cottages\",\n",
    "                \"Красота и здоровье\":\"Health and beauty\",\n",
    "                \"Аудио и видео\":\"Audio and video\",\n",
    "                \"Спорт и отдых\":\"Sports and recreation\",\n",
    "                \"Коллекционирование\":\"Collecting\",\n",
    "                \"Оборудование для бизнеса\":\"Equipment for business\",\n",
    "                \"Земельные участки\":\"Land\",\n",
    "                \"Часы и украшения\":\"Watches and jewelry\",\n",
    "                \"Книги и журналы\":\"Books and magazines\",\n",
    "                \"Собаки\":\"Dogs\",\n",
    "                \"Игры, приставки и программы\":\"Games, consoles and software\",\n",
    "                \"Другие животные\":\"Other animals\",\n",
    "                \"Велосипеды\":\"Bikes\",\n",
    "                \"Ноутбуки\":\"Laptops\",\n",
    "                \"Кошки\":\"Cats\",\n",
    "                \"Грузовики и спецтехника\":\"Trucks and buses\",\n",
    "                \"Посуда и товары для кухни\":\"Tableware and goods for kitchen\",\n",
    "                \"Растения\":\"Plants\",\n",
    "                \"Планшеты и электронные книги\":\"Tablets and e-books\",\n",
    "                \"Товары для животных\":\"Pet products\",\n",
    "                \"Комнаты\":\"Room\",\n",
    "                \"Фототехника\":\"Photo\",\n",
    "                \"Коммерческая недвижимость\":\"Commercial property\",\n",
    "                \"Гаражи и машиноместа\":\"Garages and Parking spaces\",\n",
    "                \"Музыкальные инструменты\":\"Musical instruments\",\n",
    "                \"Оргтехника и расходники\":\"Office equipment and consumables\",\n",
    "                \"Птицы\":\"Birds\",\n",
    "                \"Продукты питания\":\"Food\",\n",
    "                \"Мотоциклы и мототехника\":\"Motorcycles and bikes\",\n",
    "                \"Настольные компьютеры\":\"Desktop computers\",\n",
    "                \"Аквариум\":\"Aquarium\",\n",
    "                \"Охота и рыбалка\":\"Hunting and fishing\",\n",
    "                \"Билеты и путешествия\":\"Tickets and travel\",\n",
    "                \"Водный транспорт\":\"Water transport\",\n",
    "                \"Готовый бизнес\":\"Ready business\",\n",
    "                \"Недвижимость за рубежом\":\"Property abroad\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# not the cleanest translation, but this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train['region_en'] = train['region'].apply(lambda x : region_map[x])\n",
    "train['parent_category_name_en'] = train['parent_category_name'].apply(lambda x : parent_category_name_map[x])\n",
    "train['category_name_en'] = train['category_name'].apply(lambda x : category_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if use_test:\n",
    "    test['region_en'] = test['region'].apply(lambda x : region_map[x])\n",
    "    test['parent_category_name_en'] = test['parent_category_name'].apply(lambda x : parent_category_name_map[x])\n",
    "    test['category_name_en'] = test['category_name'].apply(lambda x : category_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                         0\n",
       "user_id                         0\n",
       "region                          0\n",
       "city                            0\n",
       "parent_category_name            0\n",
       "category_name                   0\n",
       "param_1                     14998\n",
       "param_2                    163974\n",
       "param_3                    215868\n",
       "title                           0\n",
       "description                 28920\n",
       "price                       21423\n",
       "item_seq_number                 0\n",
       "activation_date                 0\n",
       "user_type                       0\n",
       "image                       28192\n",
       "image_top_1                 28192\n",
       "deal_probability                0\n",
       "region_en                       0\n",
       "parent_category_name_en         0\n",
       "category_name_en                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 Кокоби(кокон для сна)\n",
       "1                                     Стойка для Одежды\n",
       "2                                        Philips bluray\n",
       "3                                            Автокресло\n",
       "4                                        ВАЗ 2110, 2003\n",
       "5                                           Авто люлька\n",
       "6         Водонагреватель 100 литров нержавейка плоский\n",
       "7                                      Бойфренды colins\n",
       "8                                                Платье\n",
       "9                     Полу ботиночки замш натур.Бамбини\n",
       "10                         1-к квартира, 25 м², 2/2 эт.\n",
       "11                                               Джинсы\n",
       "12                  Атласы и Контурныя карты за 8 класс\n",
       "13                                    Монитор acer 18.5\n",
       "14                     Продаются щенки немецкой овчарки\n",
       "15                                 Платье женское новое\n",
       "16                                Chevrolet Lanos, 2008\n",
       "17                                     Объемная цифра 2\n",
       "18                             Куртка весенняя(осенняя)\n",
       "19                                        Сниму коттедж\n",
       "20                         2-к квартира, 44 м², 5/5 эт.\n",
       "21                                       Шапка норковая\n",
       "22                                     Ford Focus, 2005\n",
       "23                                       Туфли moschino\n",
       "24                                    Таблетки бравекто\n",
       "25                             Пинки Пай My Little Pony\n",
       "26                                            Ламбрикен\n",
       "27                                              Ботинки\n",
       "28                                  Продаю новое платье\n",
       "29                                     Песочник Crockid\n",
       "                              ...                      \n",
       "375826                                          Ybr 125\n",
       "375827                Телевизор Thomson диагональ 70 см\n",
       "375828                               Toyota Camry, 2006\n",
       "375829                    3-к квартира, 64 м², 6/10 эт.\n",
       "375830                               Платье для девочки\n",
       "375831                    Строительство В обмен на авто\n",
       "375832                                 Джинсовый костюм\n",
       "375833                                            Флора\n",
       "375834                            Участок 10 сот. (ИЖС)\n",
       "375835                                            Брюки\n",
       "375836                             Жилет - сетка Motivi\n",
       "375837                       Торговое помещение, 400 м²\n",
       "375838                                  Комбинезон р.86\n",
       "375839                      Дом 60 м² на участке 6 сот.\n",
       "375840                               Комбинезон \"Зебра\"\n",
       "375841                                     Платье новое\n",
       "375842                                 Сандалики Сказка\n",
       "375843                              Коляска зима + лето\n",
       "375844                   Продам футболки Bonnie и Clyde\n",
       "375845                                           Платье\n",
       "375846                      Дом 45 м² на участке 8 сот.\n",
       "375847                                LADA Kalina, 2011\n",
       "375848                              Спутниковые антенны\n",
       "375849                                    Супер коляска\n",
       "375850                          Велосипед novatrack 12\"\n",
       "375851                               Сниму 1-к квартиру\n",
       "375852                                           Атлант\n",
       "375853                                              Гзш\n",
       "375854                                        Кроссовки\n",
       "375855                     Дом 40 м² на участке 30 сот.\n",
       "Name: title, Length: 375856, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "TfidfVectorizer - Vocabulary wasn't fitted.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-c4f91d1edec2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtfidf_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     full_tfidf = tfidf_vec.fit_transform(train['title'].values.tolist()\n\u001b[1;32m      5\u001b[0m                                          + test['title'].values.tolist())\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The tfidf vector is not fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m    918\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;34m\"\"\"Check if vocabulary is empty or missing (not fit-ed)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%(name)s - Vocabulary wasn't fitted.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocabulary_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: TfidfVectorizer - Vocabulary wasn't fitted."
     ]
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,1))\n",
    "train_tfidf = tfidf_vec.transform(train['title'].values.tolist())\n",
    "if use_test: \n",
    "    full_tfidf = tfidf_vec.fit_transform(train['title'].values.tolist()\n",
    "                                         + test['title'].values.tolist())\n",
    "    test_tfidf = tfidf_vec.transform(test['title'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_comp = 2\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "\n",
    "if test:\n",
    "    svd_obj.fit(full_tfidf)\n",
    "else:\n",
    "    svd_obj.fit(train_tfidf)\n",
    "    \n",
    "train_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\n",
    "train_svd.columns = ['svd_title_'+str(i+1) for i in range(n_comp)]\n",
    "train = pd.concat([train, train_svd], axis=1)\n",
    "\n",
    "if use_test:\n",
    "    test_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n",
    "    test_svd.columns = ['svd_title_'+str(i+1) for i in range(n_comp)]\n",
    "    test = pd.concat([test, test_svd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del train_tfidf, train_svd, tfidf_vec,\n",
    "if use_test:  del test_tfidf,  test_svd, full_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
